* CSCE 434
** Compiler Components
*** Compiler Overview
- Generates correct code
- Recognize legal and illegal programs
- Manage storage of variables and code
- Must understand machine code
**** Two-Pass Compilers
***** Front End
- Maps code to Intermediate Language (IL)
- Swappable
- O(n) or O(n log n)
****** Characteristics
- Recognizes Legal Entities
- Reports (preferrably helpful) Errors
- Produces IL
- Produces Preliminary Storage Map
- Shapes the Code
- Much of this can be automated
  - E.g. Flex and Bison, or Lex and YACC
****** Components
******* Scanner
- Collects input characters into *Tokens*
  - Tokens are the basic unit of syntax
  - Character string for a token is called a *Lexeme*
- Eliminates white space
- Speed is important
- Examples: number, id, +, -, do, end
******** Pattern Recognizer
********* Easy Patterns
- White spaces
- Keywords and Operators
- Comments
********* Harder Patterns
How do we identify these harder patterns?
- Identifiers
- Numbers
********* Regular Expressions
- Patterns can be specified as Regular Expressions
- Notations for Regular Language (aka Regular Set) include Regular Expressions
  and Regular Grammars
- We can use Regular Expressions to automatically build scanners
********** Order or precedence
- Closure
- Concatenation
- Alternation
******* Parser
- Recognizes Context-Free Syntax
- Gues Context-Sensitive Analysis
- Produces IL
- Produces Useful Error Messages
- Attempts Error Correction
******** Grammar
- Grammar specifies the Context-Free Syntax
- Backus-Naur Form
- Example: ~<laughter> ::= <laughter>~
  - ha or haha or hahaha etc
********* Formal
- A grammar G = (S, N, T, P)
- S is the start symbol
- N is the set of non-terminal symbols
- T is the set of terminal symbols
- P is the set of productions (rewrite rules)
******** Parse Trees
- A parse can be represented by a tree
  - also called a syntax tree
- A parse tree can be simpified into an Abstract Syntax Tree
  - Much more concise
  - Often used as the IL
***** Back End
- Maps IL to target machine
- Swappable
- NP-Complete
****** Characteristics
- Translates IL into target's Machine Code
- Chooses Instructions for each IL operation
- Decides what to store in registers and when
- Ensures conformance with system interfaces
- Automation of the Back End is less successful
******* Instruction Selection
- Produce compact, fast code
- Use available addressing modes
- Pattern matching problem
  - Ad hoc techniques
  - Tree pattern matchine
******* Register Allocation
- It's a Cache Effect!
- Goa is to always have a needed value available in a register
- Number of registers is limited
- Instrutions choice may depend on register allocation
- Moving Loads and Stores
- Difficult Problem
- NP-Compleete for 1 or k registers
**** Three-Pass Compilers
***** Middle stage is added
- Analyzes and alters IL
- Usual Goal is to reduce Runtime
- Must not make code incorrect
****** Characteristics
- Optimizer usually runs in multiple passes
- Optimizes in many ways
  - Encode idiom in a single instruction (e.g. increment)
  - Discover and propagate constants
  - Operator strength reduction (e.g. Multiplies to Adds)
  - Elimiate redundant computation
  - Eliminate common subexpressions
**** All the Compilers!
- Mixing and matching front and back ends
  - All knowledge must be encoded in the front end
  - All different language features must be in IL
  - Every backend must handle all features
- Great in theory, really hard in practice
** Front End
*** Scanner
- Must recognize various parts of the language's syntax
- Separate those parts into tokens using a scanner
**** Regular Expressions
- Regular Expressions represent languages
- Languages are sets of strings
- Operations include
  - Kleene Closure,
  - concatenation, and
  - union
**** Recognizers
- Deterministic Finite Automata (DFA) can be recognizers
***** Table Recognizers
- Recognizers can be Table-based
- Changing the tables changes the language
****** Performance Considerations
- Table-driven Implementations are Slow
- At every State Transition
- Classify input character
- Find next state
- Assign state variable
- Branch
- Evaluate case statement
******* Improve performance
- Encoding state table in scanner code improves performance
  - Classify input character
  - Test character class locally
  - Branch directly to next state
- Results in fewer instructions per cycle
**** Challenges
- Reserved words
  - PL/I has no reserved words
  - Which are reserved words, which are identifiers, which are garbage?
  - Significant Space
  - do 10 i = 1,25
- String Constants
  - Special characters in strings
- Finite closures
  - Some languages limit identifier length
- Good language design avoids these issues!
**** Lexical Errors
- Any input rejected by the lexer
  - Usually caused by running off the end of a rule
- Scanner actions
  - Report the error
  - Correct it
- Correction techniques
  - Minimum distance correction
    - Jump ahead a minimum distance
    - Pick up from there
  - Hard token recovery
    - Skip ahead to a semicolon for example
    - Pick up from there
  - SKip until match
    - Skip until you find a match for the rule
**** Project 1
- Flex is amazing!
- Start early!
- Work often!
- Check piazza
** Scanner
*** Front End
- Separates input into tokens
- Legal tokens are usually specified by REs
- RE specify regular languages
- RE are usually solved using finite memory (DFAs)
**** DFA Advantages
- Simple to implement
- Character transitions are O(1)
- Word recognitions are O(|input|)
- Construction can be automated
**** DFA Limitations
- Not all languages are regular, like HTML
- DFAs cannot count
- DFAs can pattern match!
  - Alternating 0's and 1's
  - Pairs
**** When determinism fails
- RE: (a|b)*abb
- Non-Determinism to the Rescue!
  - By using epsilon transitions
  - Can have a non-deterministic state decision between a and a|b
**** NFA vs DFA
- DFA is a special case of NFA
  - No epsilon transitions
  - Single value transition functions
- DFA can be simulated with an NFA
  - Self-evident
- NFA can be simulated with a DFA
  - Simulate sets of simultaneous states
  - Can grow exponentially large
**** Building RE from DFA and vice versa
- It is possible in both directions
** Parser
- Performs context-free syntax analysis
- Guides Syntax Analysis (SA)
- Construct _Meaningful_ intermediate representation
- Meaningful error messages
- Attempt error correction
*** Formal 
- Context Free Grammar (CFG)
- Tuple (T, NT, S, P)
  - T = Terminals (Tokens)
  - NT = Nonterminals (Syntactic Variables)
  - S = Start/Goal Symbol
  - P = Set of Productions (Rules)
*** Backus-Naur Form
- NT => Brackets or Capitals
- T => Underline, typewriter font
- P => <goal> ::= <expression>
       <expr> ::= <expr> <op> <expr> | _Number_ | _id_
*** Chomsky Hierarchy
- 0 - Turing Machine (Recursive/Unrestricted)
- 1 - Linear Bound Automata (Context-Sensitive)
- 2 - Nondeterminstic push bound automata (Context-Free)
- 3 - (Regular)
**** Regular Grammar
- Provable fact: for any R.E. r there exists a grammar g such that L(r) = L(g)
- Defs of Regular Grammar: terminal followed by nonterminal or terminal
  - A => aA
  - A => a
*** Scanning vs Parsing
- Scanning
  - Id, #, Keywords
  - No counting
  - No meaning
- Parsing
  - Order
  - Counting
  - Impart structure
  - No meaning
*** Types of Parsers
LR(k) - LR Parser, k tokens of look ahead
**** LR-Parser 
- _L_eft to Right, _R_ightmost derivation first
- Bottom-up Parse
**** LL-Parser
- _L_eft to Right, _L_eftmost derivation first
- Top-down parse
**** LALR-Parser
- _L_ook _A_head _LR_-Parser
- Not as powerful as LR(1), but more performant and powerful than standard LR
**** SLR-Parser
- Simple LR Parser
- Utilizes approximations based on the given rules
*** Complexity of Parsing
- R.E.; recognized by Discrete Finite Automata (DFAs); O(n)
- LR Grammars; Knuth's Algorithm; O(n)
- Arbitrary CFGs; Early's Algorithm; O(n^3)
- Arbitrary CSGs; LBA; P-space complete
  - probably outside P and NP, but we are not sure
  - polynomial to the input length
*** Project 2
- Due 9/20/16 midnight
- Syntax Analysis
- Piazza.com
- Turn in through csnet
- scanner.l
- parser.y
- ast.* (abstract syntax tree), not used in this project, but look at them
- implement post incr/decr and switch statement (not in the decaf spec)
- rules are on page 2 of the spec
*** Ambiguity
**** context-free
- Multiple leftmost derivations
- LL-Parsers
- If then else statements for example
  - <Stmt> -> <M> | <N>
    <N>    -> if <expr> then <N> else <N> | other stuff
    <M>    -> if <expr> then <Stmt> |
              if <expr> then <N> else <M>
**** context-sensitive
- overloading
  A = f(17)
- Is that f a function or an array with a subscript
- It depends on what value A is or what it's type is
*** LL-Parsers vs LR-Parsers
**** LL: Top-Down 
- Start at root of tree (start symbol)
- May backtrack
  - Some grammars are backtrack-free, otherwise called *predictive*
***** Process
1. Start at node A
   - Select Production
     - A on left hand side
     - For each symbol on the right hand side
       - Process it
2. When a terminal is next in the production that doesn't match the input
   - *Backtrack*
3. Find the next node
   - go back to 1.
***** Problem of left recursion
- A grammar $G$ is left recursive if $\exists A \in NT$ s.t. there exists a
  derivation $A \rightarrow^+\alpha$ for some =string= $\alpha$
- This can cause infinite loop
- Solution: use right recursion instead
  - Now, be careful not to screw up associativity and therefore precedence
    - Arrange nonterminals $A_0\ldotsA_n$ in some order
**** LR: Bottom-Up
- Start at leaves (end at goal symbol)
- Start in valid state
- Requires a stack to keep track of state and sentence forms
*** Look-Ahead
